### Отчет по `src/preprocess.py`

**Роль скрипта в проекте**  
Скрипт выполняет **предобработку датасета LibriSpeech** для задачи регрессии по **скорости речи (CPS — characters per second)**.  
Он:
1. Проходит по структуре папок `train-clean-100`, `dev-clean`, `test-clean`.
2. Читает `.trans.txt` — файлы с транскрипциями.
3. Для каждого аудио `.flac`:
   - Загружает звук через `pydub`.
   - Считает длительность в секундах.
   - Подсчитывает количество **алфавитно-цифровых символов** в тексте (`isalnum()`).
   - Вычисляет **CPS = символы / секунды**.
4. Сохраняет результаты в **CSV-файлы** в `data/processed/`:
   - `train_cps.csv`
   - `dev_cps.csv`
   - `test_cps.csv`

---

**Формат выходных данных (CSV)**  
Каждая строка — один аудиосэмпл:

| Поле          | Тип     | Описание |
|---------------|---------|---------|
| `audio_path`  | str     | Путь к `.flac` |
| `text`        | str     | Полный текст транскрипции |
| `cps`         | float   | **Целевой признак**: буквы/цифры в секунду |
| `speaker_id`  | str     | ID спикера |
| `chapter_id`  | str     | ID главы |
| `audio_id`    | str     | ID аудио |

---

**Ключевые особенности**
- Используется **только alnum-символы** (буквы + цифры), пробелы и знаки игнорируются.
- Обработка с `tqdm` — видно прогресс.
- Логирование ошибок (файлы не найдены, формат строки и т.д.).
- Запуск через CLI:  
  ```bash
  poetry run python src/preprocess.py --data_dir data/raw --output_dir data/processed
  ```

---

**Связь с дальнейшими шагами**
- Эти **CSV — источник лейблов** для `extract_embeddings.py` и `train_model.py`.
- `audio_path` используется для извлечения эмбеддингов.
- `cps` — **целевая переменная регрессии**.

**Вывод**: скрипт полностью готовит **обучающую выборку с целевым признаком CPS** в удобном табличном формате.  
Следующий шаг — извлечение эмбеддингов по `audio_path` и обучение MLP на предсказание `cps`.