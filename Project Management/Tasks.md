### Задания по пунктам

#### Задание 1: Выбор признака и подготовка
- Выбрать признак для анализа в нейронных сетях (скорость речи) и записаться в таблицу Google Sheets.
- Найти датасет с речью и разметкой (текстом высказываний для расчета скорости в буквах/секунду).
- Посчитать скорость речи для каждого сэмпла как количество букв / длительность аудио.
- Решить задачу регрессии: подать эмбеддинги в MLP для предсказания непрерывного значения скорости (без классов).
- Подумать о подходе: использовать эмбеддинги спикера из модели, обучить MLP на регрессию, оценить метриками (MSE, MAE).

#### Задание 2: Работа с репозиторием и эмбеддингами
- Создать форк репозитория https://github.com/KORALLLL/interp_dev.
- Склонировать форк локально.
- Скачать веса модели SimAMResNet34 vb (voxblink2_samresnet34.zip) от WeNet.
- Модифицировать extract_embeddings.py: вычислить эмбеддинги и лейблы (значения скорости речи) для датасета.
- Посчитать и сохранить эмбеддинги.
- Модифицировать train_model.py для регрессии: изменить выход MLP на 1 нейрон, loss на MSE.
- Обучить MLP на эмбеддингах.
- Сохранить обученную модель.
- Получить метрики (MSE, MAE).
- Модифицировать код визуализации (t-SNE для эмбеддингов).
- Сохранить визуализацию.
- Отправить датасет в беседу.
- Запушить изменения, визуализацию и веса в форк (папка: speech_speed).
- Создать pull request в оригинальный репозиторий.
- Уведомить о PR для ревью.

#### Задание 3: Анализ моделей WeSpeaker
- Работать с моделями: SimAMResNet34 vb, SimAMResNet34 vb+vc, SimAMResNet100 vb, SimAMResNet100 vc.
- Дедлайн 1 мая: PR с одной моделью (на выбор).
- Дедлайн 15 мая: результаты по всем моделям.
- Для топика "скорость речи" (регрессия): использовать acts_probing.py.
- Получить активации слоев с помощью GetActivations для каждого сэмпла датасета.
- Сохранить активации по слоям отдельно.
- Для каждого слоя: обучить MLP на регрессию по активациям, получить метрики (MSE, MAE).
- Построить график изменения метрик по слоям.
- Модифицировать папку в репозитории: добавить код, график.
- Создать PR с обновлениями.

#### Дополнительное задание (extra): Мини-статья
- Написать статью на русском в LaTeX (Overleaf, шаблон NeurIPS или IEEE, две колонки).
- Название, автор (вы с МТУСИ и почтой).
- Объем: 2-4 страницы без приложений.
- Секции:
  - Abstract: задача, важность, методы, результаты, вклад (до 300 слов).
  - Introduction: суть работы, проблема, цель, связанные работы, отличие, вклад; краткий обзор статьи.
  - Methodology: датасет (статистика, сбор, предобработка, таблицы/рисунки); модель (архитектура, обоснование); эмбеддинги, MLP (регрессия), метрики, визуализация (t-SNE), послойный анализ.
  - Experiments and results: результаты по этапам (метрики на эмбеддингах, t-SNE, метрики по слоям, сравнение моделей); анализ графиков/таблиц, закономерности, ограничения, улучшения.
  - Conclusion: задача, выводы, вклад, перспективы.
  - References: ссылки на модели, датасеты, методы (английские публикации, использовать \cite).
- Добавить графики, таблицы с подписями и ссылками в тексте.
- Сдать индивидуально для шанса на менторство (первые 3 идеальных).

### План решения
1. Установить poetry в проекте (poetry init, добавить зависимости: torch, numpy, scikit-learn, matplotlib, librosa).
2. Для датасета: использовать LibriSpeech (raw в data/raw: train-clean-100, dev-clean, test-clean); скачать тексты, посчитать скорость в src/preprocess.py (letters / duration).
3. Извлечь эмбеддинги: запустить модифицированный extract_embeddings.py, сохранить в data/processed.
4. Обучить MLP: в train_model.py изменить на регрессию (nn.MSELoss), train/test split, сохранить модель в models.
5. Визуализация: t-SNE эмбеддингов, сохранить в results.
6. Послойный анализ: для каждой модели получить активации, обучить MLP по слоям, построить графики метрик, сохранить в results.
7. PR: создать ветку speech_speed, push изменения, PR в оригинал.
8. Статья: в Overleaf создать проект, заполнить секции на основе результатов, добавить цитаты.