### Отчет по файлу `train_models.py`

**Роль скрипта в проекте**  
Скрипт отвечает за обучение MLP-пробинга на эмбеддингах WeSpeaker для **регрессии скорости речи (CPS — букв в секунду)**.  
Он используется на двух этапах:  
1. Обучение на **готовых эмбеддингах** (из `data/processed`).  
2. Обучение **пробинга по активациям слоев** (для послойного анализа, Задание 3).  

---

**Формат входных данных (DataLoader)**  

| Параметр | Тип | Описание |
|--------|-----|---------|
| `embeddings_batch` / `X_batch` | `torch.FloatTensor` | shape: `(batch_size, embedding_dim)` — эмбеддинги спикера (например, 256 для ResNet34). |
| `labels_batch` / `y_batch` | `torch.FloatTensor` | shape: `(batch_size,)` — **скорость речи в буквах/секунду** (непрерывное значение). |

> Данные формируются в `extract_embeddings.py` (для эмбеддингов) и `preprocess.py` (для CPS-лейблов), объединяются в `Dataset` → `DataLoader`.

---

**Ключевые функции**

1. **`train_emb_model`**  
   - Используется для обучения **на готовых эмбеддингах**.  
   - Модель возвращает `_, outputs` → предполагает, что `ProbingCls` возвращает два значения (возможно, совместимость с классификацией).  
   - Loss: `MSELoss`, выход сжимается `.squeeze(1)` → 1 значение на сэмпл.

2. **`train_probing_model`**  
   - Универсальная функция для **пробинга по любому слою**.  
   - Создает `ProbingCls(input_dim)` → MLP с входом = размерности активаций.  
   - Loss: `MSELoss`, обучение с Adam (lr=3e-4), 3 эпохи по умолчанию.  
   - Возвращает обученную модель.

---

**Выводы и замечания**

- Скрипт **уже адаптирован под регрессию** — использует `MSELoss`, `.float()` для лейблов, выход 1 нейрон.  
- Подходит как для **эмбеддингов**, так и для **активаций слоев** (меняется только `input_dim`).  
- Для послойного анализа (Задание 3):  
  - Передавать `activations` вместо эмбеддингов.  
  - Сохранять метрики (MSE, MAE) после обучения.  
- Рекомендация: добавить **валидацию** и **расчет метрик** (MAE, R²) — сейчас только обучение.

**Итог**: файл — ядро обучения пробинга, полностью соответствует задаче регрессии скорости речи. Готов к использованию в `train_model.py` и `acts_probing.py`.