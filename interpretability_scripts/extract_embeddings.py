import argparse
import os
from pathlib import Path
import pandas as pd
import numpy as np
import chromadb
import torch
from tqdm import tqdm
import wespeaker
import inspect


def get_audio_files_from_csv(csv_path):
    """
    Reads audio file paths from a CSV file generated by preprocess.py.

    :param csv_path: Path to the CSV file (e.g., data/processed/train_cps.csv)
    :return: List of audio file paths
    """
    df = pd.read_csv(csv_path)
    return df['audio_path'].tolist()


def assign_labels_by_speaker_id(embeddings, csv_path):
    """
    Assigns labels to embeddings based on speaker_id from the CSV file.

    :param embeddings: List of dictionaries with 'file_path' and 'embedding'
    :param csv_path: Path to the CSV file containing speaker_id
    """
    df = pd.read_csv(csv_path)
    path_to_speaker = {row['audio_path']: row['speaker_id'] for _, row in df.iterrows()}

    for emb in embeddings:
        emb['label'] = path_to_speaker.get(emb['file_path'], 'unknown')


def save_to_npy(embeddings, save_dir):
    """
    Saves embeddings in .npy format.

    :param embeddings: List of dictionaries containing train and test embeddings
    :param save_dir: Directory to save the .npy file
    """
    os.makedirs(save_dir, exist_ok=True)
    np.save(os.path.join(save_dir, "numpy_embs.npy"), np.array(embeddings, dtype=object))


def save_to_chromadb(embeddings, db_path, split):
    """
    Stores embeddings in ChromaDB.

    :param embeddings: List of dictionaries with 'file_path', 'embedding', and 'label'
    :param db_path: Path to ChromaDB storage
    :param split: Dataset split (train/test/dev)
    """
    client = chromadb.PersistentClient(path=db_path)
    collection = client.get_or_create_collection(name="gender_embeddings")

    collection.add(
        ids=[f"{split}_{i}" for i in range(len(embeddings))],
        embeddings=[item['embedding'] for item in embeddings],
        metadatas=[{
            "file_path": item['file_path'],
            "label": item['label'],
            "split": split
        } for item in embeddings]
    )


def extract_embeddings(audio_files, device, pretrain_dir):
    """
    Extracts embeddings from audio files using the WeSpeaker model.

    :param audio_files: List of audio file paths
    :param device: Device to run the model on (cuda/cpu)
    :param pretrain_dir: Path to the pretrained WeSpeaker model
    :return: List of dictionaries with 'file_path' and 'embedding'
    """
    # print("Available methods:", [method for method in dir(wespeaker) if not method.startswith('_')])
    # signature = inspect.signature(wespeaker.load_model)
    # print(signature)

    model = wespeaker.load_model(pretrain_dir)
    # print("Available methods:", [method for method in dir(model) if not method.startswith('_')])

    model.set_device(device)

    embeddings = []

    for file_path in tqdm(audio_files, desc="Embeddings computing process"):
        embedding = model.extract_embedding(file_path)
        embedding = embedding.cpu().numpy()
        embeddings.append({
            'file_path': str(file_path),
            'embedding': embedding
        })
    return embeddings


def main():
    """
    Main function to extract embeddings from audio files listed in CSV files
    and save them in the specified format.
    """
    parser = argparse.ArgumentParser(description="Extract embeddings from LibriSpeech audio files listed in CSV.")
    parser.add_argument("--data_dir", type=str, default="data/processed",
                        help="Path to directory with processed CSV files (train_cps.csv, test_cps.csv, dev_cps.csv).")
    parser.add_argument("--pretrain_dir", type=str, default="./pretrain_dir",
                        help="Path to wespeaker model pretrain_dir.")
    parser.add_argument("--output", type=str, required=True, choices=["npy", "chromadb"],
                        help="Embeddings saving format: npy or chromadb.")
    parser.add_argument("--save_path", type=str, default="./embeddings",
                        help="Save path for calculated embeddings.")
    args = parser.parse_args()

    csv_files = {
        'train': os.path.join(args.data_dir, 'train_cps.csv'),
        'test': os.path.join(args.data_dir, 'test_cps.csv'),
        'dev': os.path.join(args.data_dir, 'dev_cps.csv')
    }

    for split, csv_path in csv_files.items():
        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"CSV file {csv_path} does not exist.")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    embeddings_dict = {}
    for split, csv_path in csv_files.items():
        audio_files = get_audio_files_from_csv(csv_path)
        embeddings = extract_embeddings(audio_files, device, args.pretrain_dir)
        assign_labels_by_speaker_id(embeddings, csv_path)
        embeddings_dict[split] = embeddings

    if args.output == "npy":
        save_to_npy(embeddings_dict, args.save_path)
    elif args.output == "chromadb":
        for split, embeddings in embeddings_dict.items():
            save_to_chromadb(embeddings, args.save_path, split)


if __name__ == '__main__':
    main()